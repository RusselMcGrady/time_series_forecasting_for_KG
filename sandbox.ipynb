{"cells":[{"cell_type":"markdown","metadata":{"id":"Gwo9bpaVgxXF"},"source":["##Setup\n","\n","You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4550,"status":"ok","timestamp":1681455511227,"user":{"displayName":"McGrady Russell","userId":"08177265580327885764"},"user_tz":-480},"id":"6CAdiyTKi4Se","outputId":"0c0013b0-d1ff-473e-cc75-db397ac34df5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["#@title mount your Google Drive\n","#@markdown Your work will be stored in a folder called `STGAT` by default to prevent Colab instance timeouts from deleting your edits.\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681455511227,"user":{"displayName":"McGrady Russell","userId":"08177265580327885764"},"user_tz":-480},"id":"BKE5nA1Fgwwy"},"outputs":[],"source":["#@title set up mount symlink\n","## change to your own path\n","DRIVE_PATH = '/content/gdrive/MyDrive/Colab\\ Notebooks/transformer_time_series-main'\n","DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n","if not os.path.exists(DRIVE_PYTHON_PATH):\n","  %mkdir $DRIVE_PATH\n","\n","## the space in `My Drive` causes some issues,\n","## make a symlink to avoid this\n","SYM_PATH = '/content/transformer-series'\n","if not os.path.exists(SYM_PATH):\n","  !ln -s $DRIVE_PATH $SYM_PATH"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6102,"status":"ok","timestamp":1681455517325,"user":{"displayName":"McGrady Russell","userId":"08177265580327885764"},"user_tz":-480},"id":"9FGK4kbpg3iP","outputId":"569482c9-5f30-415a-9cfd-58ae1e60e014"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.9/dist-packages (2.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"]}],"source":["#@title apt install requirements\n","\n","#@markdown Run each section with Shift+Enter\n","\n","#@markdown Double-click on section headers to show code.\n","\n","#!apt update \n","#!apt install -y --no-install-recommends\n","#!python -m pip install ipykernel\n","#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install torch-geometric transformers"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1681455517326,"user":{"displayName":"McGrady Russell","userId":"08177265580327885764"},"user_tz":-480},"id":"YNGuuABeg99q","outputId":"d5722262-f707-4b37-9de2-566f0dc86745"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/.shortcut-targets-by-id/1B5DjVHnJIRbNAxTrvu53Vw0QElUaY6IQ/transformer_time_series-main\n","\u001b[0m\u001b[01;34mdata\u001b[0m/                            requirements.txt\n","inference_sandbox3D.py           sandbox3D.py\n","inference_sandbox4D.py           sandbox3Dpy\n","inference_sandbox.py             sandbox4D.py\n","inference_sandbox_univariate.py  sandbox.ipynb\n","\u001b[01;34mlayer\u001b[0m/                           sandbox.py\n","\u001b[01;34mmodel\u001b[0m/                           sandbox_univariate.py\n","\u001b[01;34moutput\u001b[0m/                          transformer_time_series-main.zip\n","\u001b[01;34m__pycache__\u001b[0m/                     \u001b[01;34mutil\u001b[0m/\n","README.md\n"]}],"source":["#@title clone homework repo\n","\n","%cd $SYM_PATH\n","%ls"]},{"cell_type":"markdown","metadata":{"id":"mZ0atmcpt8E5"},"source":["### train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":2387,"status":"error","timestamp":1681455519707,"user":{"displayName":"McGrady Russell","userId":"08177265580327885764"},"user_tz":-480},"id":"9Nj3QDO_lCww","outputId":"7c320d36-dd0a-4de3-80f0-d42f2a830786"},"outputs":[],"source":["\"\"\"\n","Showing how to use the model with some time series data.\n","\n","NB! This is not a full training loop. You have to write the training loop yourself. \n","\n","I.e. this code is just a starting point to show you how to initialize the model and provide its inputs\n","\n","If you do not know how to train a PyTorch model, it is too soon for you to dive into transformers imo :) \n","\n","You're better off starting off with some simpler architectures, e.g. a simple feed forward network, in order to learn the basics\n","\"\"\"\n","\n","import util.dataset as ds\n","import util.utils as utils\n","import torch\n","import datetime\n","import time\n","import layer.TransformerGAT as tst\n","import numpy as np\n","import math\n","import pandas as pd\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import LambdaLR\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","SCALER = True\n","LINEAR_DECODER = False\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def train(model, training_time_data, src_mask, tgt_mask, loss_fn, optimizer, scheduler, batch_first, batch_size, input_size):\n","    model.train() # Turn on the train mode \\o/\n","    start_time = time.time()\n","    total_loss = 0.\n","\n","    for step, batch in enumerate(training_time_data):\n","        optimizer.zero_grad()\n","        \n","        src, trg, trg_y = batch\n","        B, N, T, F = trg_y.size()\n","        if input_size == 1:\n","            trg_y.unsqueeze(-1) # feature size = 1\n","        src, trg, trg_y = src.to(device), trg.to(device), trg_y.to(device)\n","\n","        # Split the data tensor along dimension 1 into smaller tensors\n","        src_chunks, trg_chunks, trg_y_chunks = src.chunk(src.size(1) // batch_size, dim=1), trg.chunk(trg.size(1) // batch_size, dim=1), trg_y.chunk(trg_y.size(1) // batch_size, dim=1)\n","        # Create a list of TensorDatasets\n","        minibatch_datasets = [TensorDataset(src_chunk, trg_chunk, trg_y_chunk) for src_chunk, trg_chunk, trg_y_chunk in zip(src_chunks, trg_chunks, trg_y_chunks)]\n","\n","        # Create a list of DataLoaders\n","        minibatch_dataloaders = [DataLoader(minibatch_dataset, batch_size=batch_size, shuffle=False) for minibatch_dataset in minibatch_datasets]\n","\n","        for minibatch_dataloader in minibatch_dataloaders:\n","            for minibatch_idx, (src, trg, trg_y) in enumerate(minibatch_dataloader):\n","\n","                # Permute from shape [series batch size, node minibatch size, seq len, num features] to [seq len, series batch size*node minibatch size, num features]\n","                # Node dimension is put inside the batch, in order to process each node along the time separately\n","                if batch_first == False:\n","                    src = src.permute(2, 0, 1, 3)\n","                    src = src.reshape(src.size()[0], src.size()[1] * src.size()[2], src.size()[3])\n","                    # print(\"src shape changed from {} to {}\".format(shape_before, src.shape))\n","\n","                    trg = trg.permute(2, 0, 1, 3)\n","                    trg = trg.reshape(trg.size()[0], trg.size()[1] * trg.size()[2], trg.size()[3])\n","\n","                    trg_y = trg_y.permute(2, 0, 1, 3)\n","                    trg_y = trg_y.reshape(trg_y.size()[0], trg_y.size()[1] * trg_y.size()[2], trg_y.size()[3])\n","\n","                output = model(\n","                    src=src,\n","                    tgt=trg,\n","                    src_mask=src_mask,\n","                    tgt_mask=tgt_mask,\n","                    linear_decoder=LINEAR_DECODER\n","                )\n","                # output = output.permute(1, 0, 2).squeeze()\n","                # print(f'output:', output.size())\n","                if batch_first == False:\n","                    output = output.permute(1, 0, 2)\n","                    trg_y = trg_y.permute(1, 0, 2)\n","            \n","                loss = loss_fn(output, trg_y)\n","                loss.backward()\n","                optimizer.step()\n","                total_loss += loss.item()\n","\n","        ave_node_loss = total_loss / N\n","        elapsed = time.time() - start_time\n","        print('| epoch {:3d} | step {:3d} | '\n","                'lr {:02.8f} | {:5.2f} ms | '\n","                'batch node loss {:5.5f} | ppl {:8.2f}'.format(\n","                epoch, step, scheduler.get_last_lr()[0], # get_lr()\n","                elapsed * 1000, ave_node_loss, math.exp(ave_node_loss))) # math.log(cur_loss)\n","        \n","    total_loss = 0\n","    start_time = time.time()\n","    scheduler.step()\n","\n","    # print('-'*12)\n","    # print(scaler.inverse_transform(output.reshape(-1, 5).detach().cpu()))\n","    # print('-'*12)\n","    # print(scaler.inverse_transform(trg_y.reshape(-1, 5).detach().cpu()))\n","    # print('-'*12)\n","    return output\n","\n","# Hyperparams\n","test_size = 0.2\n","batch_size = 32\n","target_col_name = \"Reliability\"\n","timestamp_col = \"Timestamp\"\n","node_col = \"Node\"\n","# Only use data from this date and onwards\n","cutoff_date = datetime.datetime(2017, 1, 1) \n","\n","## Params\n","dim_val = 512\n","n_heads = 8\n","n_decoder_layers = 4\n","n_encoder_layers = 4\n","dec_seq_len = 1 # length of input given to decoder 92\n","enc_seq_len = 5 # length of input given to encoder 153\n","output_sequence_length = 1 # target sequence length. If hourly data and length = 48, you predict 2 days ahead 48\n","if LINEAR_DECODER:\n","    output_sequence_length = enc_seq_len\n","window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n","step_size = 1 # Step size, i.e. how many time steps does the moving window move at each step\n","in_features_encoder_linear_layer = 2048\n","in_features_decoder_linear_layer = 2048\n","max_seq_len = enc_seq_len\n","batch_first = False\n","\n","# Define input variables \n","exogenous_vars = ['Flexibility','Service','Infrastructure Quality','Freight'] # should contain strings. Each string must correspond to a column name\n","input_variables = [target_col_name] + exogenous_vars\n","target_idx = 0 # index position of target in batched trg_y\n","\n","input_size = len(input_variables)\n","\n","# Read data\n","# Input x\n","# (batch_size, nodes, sequentials, features)\n","data, slice_size = utils.read_data(file_name='forecast_cyclical_data', node_col_name=node_col, timestamp_col_name=timestamp_col)\n","\n","# Remove test data from dataset for each node\n","ratio = round(slice_size*(1-test_size))\n","first_round = data.iloc[0:ratio, :]\n","for i in range(1,round(len(data)//slice_size)+1):\n","    first_round = pd.concat([first_round, data.iloc[slice_size*i:slice_size*i+ratio, :]], axis=0)\n","training_time_data = first_round\n","training_slice_size = ratio\n","\n","# Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chunkc. \n","# Should be training time series data indices only\n","training_indices = utils.get_indices_entire_sequence(\n","    data=training_time_data, \n","    window_size=window_size, \n","    step_size=step_size,\n","    slice_size=training_slice_size)\n","\n","# looks like normalizing input values curtial for the model\n","scaler = MinMaxScaler(feature_range=(-1, 1))\n","# scaler = StandardScaler()\n","# Recover the original values\n","# original_data = scaler.inverse_transform(scaled_data)\n","series = training_time_data[input_variables].values\n","\n","# for i, val in enumerate(series.mean(axis=0)):\n","#      series[:,i][series[:,i] == 0] = val\n","# series = np.where(series == 0, 1e-9, series)\n","\n","if SCALER:\n","    amplitude = scaler.fit_transform(series)\n","else:\n","    amplitude = series\n","    \n","# Making instance of custom dataset class\n","training_time_data = ds.TransformerDataset( ## todo\n","    data=torch.tensor(amplitude).float(),\n","    indices=training_indices,\n","    enc_seq_len=enc_seq_len,\n","    dec_seq_len=dec_seq_len,\n","    target_seq_len=output_sequence_length,\n","    slice_size=training_slice_size\n","    )\n","\n","# Making dataloader\n","training_time_data = DataLoader(training_time_data, batch_size, shuffle=False) #cannot shuffle time series\n","\n","model = tst.TimeSeriesTransformer(\n","    input_size=len(input_variables),\n","    batch_first=batch_first,\n","    num_predicted_features=len(input_variables) # 1 if univariate\n","    ).to(device)\n","\n","\n","# Make src mask for decoder with size:\n","# [batch_size*n_heads, output_sequence_length, enc_seq_len]\n","src_mask = utils.generate_square_subsequent_mask(\n","    dim1=output_sequence_length,\n","    dim2=enc_seq_len\n","    ).to(device)\n","\n","# Make tgt mask for decoder with size:\n","# [batch_size*n_heads, output_sequence_length, output_sequence_length]\n","tgt_mask = utils.generate_square_subsequent_mask( \n","    dim1=output_sequence_length,\n","    dim2=output_sequence_length\n","    ).to(device)\n","\n","# loss_fn = torch.nn.HuberLoss().to(device)\n","loss_fn = torch.nn.MSELoss().to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","\n","# Define the warm-up schedule\n","num_epochs = 1000 # 50\n","# total_steps = len(training_time_data) * num_epochs\n","# Create the scheduler\n","# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=5, num_training_steps=num_epochs)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95)\n","\n","\n","for epoch in range(num_epochs):\n","    output = train(model, training_time_data, src_mask, tgt_mask, loss_fn, optimizer, scheduler, batch_first, batch_size, input_size)\n","\n","    if epoch == num_epochs-1:\n","        print('hidden embeddings of epoch {}: {}'.format(epoch, output))\n","            \n","    if (epoch+1) % 10 == 0:\n","        # Save the model\n","        torch.save(model.state_dict(), 'model/model4D_{}_{}.pth'.format(enc_seq_len, output_sequence_length))\n","        # model.load_state_dict(torch.load('model.pth'))"]},{"cell_type":"markdown","metadata":{"id":"Jm5Ng2-Swlop"},"source":["### test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJSmo_9gwVE2"},"outputs":[],"source":["\"\"\"\n","code-ish example of how to use the inference function to do validation\n","during training. \n","\n","The validation loop can be used as-is for model testing as well.\n","\n","NB! You cannot use this script as is. This is merely an example to show the overall idea - \n","not something you can copy paste and expect to work. For instance, see \"sandbox.py\" \n","for example of how to instantiate model and generate dataloaders.\n","\n","If you have never before trained a PyTorch neural network, I suggest you look\n","at some of PyTorch's beginner-level tutorials.\n","\"\"\"\n","import torch\n","import util.inference as inference\n","import util.utils as utils\n","import layer.TransformerGAT as tst\n","import numpy as np\n","import util.dataset as ds\n","import pandas as pd\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","\n","PLOT_BIAS = True\n","PLOT_PREDICT = True\n","SCALER = True\n","LINEAR_DECODER = False\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def eval(model, test_time_data, src_mask, tgt_mask, loss_fn, batch_first, batch_size, input_size, PLOT_BIAS, PLOT_PREDICT, SCALER):\n","    # Set the model to evaluation mode\n","    model.eval()\n","    output = torch.Tensor(0)    \n","    truth = torch.Tensor(0)\n","    output_scale = torch.Tensor(0)\n","    truth_scale = torch.Tensor(0)\n","    total_loss = 0.\n","\n","    for step, batch in enumerate(test_time_data):\n","\n","        src, trg, trg_y = batch\n","        B, N, T, F = trg_y.size()\n","        if input_size == 1:\n","            trg_y.unsqueeze(2) # feature size = 1\n","        src, trg, trg_y = src.to(device), trg.to(device), trg_y.to(device)\n","        \n","        # Split the data tensor along dimension 1 into smaller tensors\n","        src_chunks, trg_chunks, trg_y_chunks = src.chunk(src.size(1) // batch_size, dim=1), trg.chunk(trg.size(1) // batch_size, dim=1), trg_y.chunk(trg_y.size(1) // batch_size, dim=1)\n","        # Create a list of TensorDatasets\n","        minibatch_datasets = [TensorDataset(src_chunk, trg_chunk, trg_y_chunk) for src_chunk, trg_chunk, trg_y_chunk in zip(src_chunks, trg_chunks, trg_y_chunks)]\n","\n","        # Create a list of DataLoaders, shuffle node mini batches\n","        minibatch_dataloaders = [DataLoader(minibatch_dataset, batch_size=batch_size, shuffle=False) for minibatch_dataset in minibatch_datasets]\n","\n","        for minibatch_dataloader in minibatch_dataloaders:\n","            for minibatch_idx, (src, trg, trg_y) in enumerate(minibatch_dataloader):\n","\n","                # Permute from shape [batch size, node size, seq len, num features] to [seq len, batch size*node size, num features]\n","                # Node dimension is put inside the batch, in order to process each node along the time separately\n","                if batch_first == False:\n","                    src = src.permute(2, 0, 1, 3)\n","                    src = src.reshape(src.size()[0], src.size()[1] * src.size()[2], src.size()[3])\n","                    # print(\"src shape changed from {} to {}\".format(shape_before, src.shape))\n","\n","                    trg = trg.permute(2, 0, 1, 3)\n","                    trg = trg.reshape(trg.size()[0], trg.size()[1] * trg.size()[2], trg.size()[3])\n","\n","                    trg_y = trg_y.permute(2, 0, 1, 3)\n","                    trg_y = trg_y.reshape(trg_y.size()[0], trg_y.size()[1] * trg_y.size()[2], trg_y.size()[3])\n","\n","                # inference on the length of the output window\n","                prediction = model(\n","                    src=src,\n","                    tgt=trg,\n","                    src_mask=src_mask,\n","                    tgt_mask=tgt_mask,\n","                    linear_decoder=LINEAR_DECODER\n","                )\n","\n","                if batch_first == False: # must permute the dimension for plot\n","                    prediction = prediction.permute(1, 0, 2)\n","                    trg_y = trg_y.permute(1, 0, 2)\n","\n","                total_loss += loss_fn(prediction, trg_y).item()\n","\n","                # for evaluating metrics\n","                output_scale = torch.cat((output_scale, prediction.reshape(-1, input_size).detach().cpu()))\n","                truth_scale = torch.cat((truth_scale, trg_y.reshape(-1, input_size).detach().cpu()))\n","\n","                # operation reshape(-1, input_size) concat the sequential data in  the form of time series\n","                if SCALER:\n","                    output = torch.cat((output, torch.tensor(scaler.inverse_transform(prediction.reshape(-1, input_size).detach().cpu())).cpu()), 0)\n","                    truth = torch.cat((truth, torch.tensor(scaler.inverse_transform(trg_y.reshape(-1, input_size).detach().cpu())).contiguous().cpu()), 0)\n","                else:\n","                    output = torch.cat((output, prediction.reshape(-1, input_size).cpu()), 0)\n","                    truth = torch.cat((truth, trg_y.reshape(-1, input_size).contiguous().cpu()), 0)    \n","               \n","\n","    if PLOT_BIAS == True:\n","        plot_length = len(output)\n","        utils.plot(output, truth, step, plot_length, total_loss/plot_length)\n","    \n","    if PLOT_PREDICT == True:\n","        if batch_first == False:\n","            batch_size = src.size()[1]\n","        else:\n","            batch_size = src.size()[0]\n","        # inference one by one\n","        forecast = inference.run_encoder_decoder_inference(\n","            model=model, \n","            src=src, \n","            forecast_window=forecast_window,\n","            batch_size=batch_size,\n","            device=device,\n","            batch_first=batch_first\n","            ) # predict forecast_window steps\n","        \n","        if batch_first == False: # must permute the dimension for plot\n","            forecast = forecast.permute(1, 0, 2)\n","            src = src.permute(1, 0, 2)\n","        if SCALER: # recover scaled data\n","            src = torch.tensor(scaler.inverse_transform(src[-1,:,].detach().cpu()))\n","            forecast = torch.tensor(scaler.inverse_transform(forecast[-1,:,].detach().cpu()))\n","        else:\n","            src = src[-1,:,].cpu()\n","            forecast = forecast[-1,:,].cpu()\n","\n","        utils.predict_future(src.unsqueeze(0), forecast.unsqueeze(0))\n","\n","    # reshape(B, N, T, F)\n","    # print('output tensor in shape (N, B, T, F): \\n',output.reshape(B, N, T, F))\n","    utils.evaluate_forecast(truth_scale, output_scale)\n","        \n","\n","# Hyperparams\n","target_col_name = \"Reliability\"\n","timestamp_col = \"Timestamp\"\n","node_col = \"Node\"\n","test_size = 0.2\n","batch_size = 64\n","\n","## Params\n","dim_val = 512\n","n_heads = 8\n","n_decoder_layers = 4\n","n_encoder_layers = 4\n","enc_seq_len = 5 # supposing you want the model to base its forecasts on the previous 7 days of data\n","output_sequence_length = 1 # supposing you're forecasting 48 hours ahead\n","if LINEAR_DECODER:\n","    output_sequence_length = enc_seq_len\n","forecast_window = 4\n","window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n","step_size = 1 # Step size, i.e. how many time steps does the moving window move at each step\n","in_features_encoder_linear_layer = 2048\n","in_features_decoder_linear_layer = 2048\n","max_seq_len = enc_seq_len\n","batch_first = False\n","\n","# Define input variables \n","exogenous_vars = ['Flexibility','Service','Infrastructure Quality','Freight'] # should contain strings. Each string must correspond to a column name\n","input_variables = [target_col_name] + exogenous_vars\n","input_size = len(input_variables)\n","\n","# Read data\n","# Input x\n","# (batch_size, nodes, sequentials, features)\n","data, slice_size = utils.read_data(file_name='forecast_cyclical_data_test', node_col_name=node_col, timestamp_col_name=timestamp_col)\n","\n","# Get test data from dataset\n","ratio = round(slice_size*test_size)\n","first_round = data.iloc[slice_size-ratio:slice_size, :]\n","for i in range(1,round(len(data)//slice_size)+1):\n","    first_round = pd.concat([first_round, data.iloc[slice_size*(i+1)-ratio:slice_size*(i+1), :]], axis=0)\n","test_time_data = first_round\n","test_slice_size = ratio\n","# test_time_data = data[-(round(len(data)*test_size)):]\n","\n","# Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chunkc. \n","# Should be test data indices only\n","test_indices = utils.get_indices_input_target(\n","    num_obs=len(test_time_data), # round(len(data)*test_size)\n","    input_len=window_size,\n","    step_size=window_size,\n","    forecast_horizon=0,\n","    target_len=output_sequence_length,\n","    slice_size=test_slice_size\n",")\n","\n","# looks like normalizing input values curtial for the model\n","scaler = MinMaxScaler(feature_range=(-1, 1))\n","# scaler = StandardScaler()\n","# Recover the original values\n","# original_data = scaler.inverse_transform(scaled_data)\n","series = test_time_data[input_variables].values\n","if SCALER:\n","    amplitude = scaler.fit_transform(series)\n","else:\n","    amplitude = series\n","\n","# Making instance of custom dataset class\n","test_time_data = ds.TransformerDataset(\n","    data=torch.tensor(amplitude).float(),\n","    indices=test_indices,\n","    enc_seq_len=enc_seq_len,\n","    dec_seq_len=output_sequence_length,\n","    target_seq_len=output_sequence_length,\n","    slice_size=test_slice_size\n","    )\n","\n","# Making dataloader\n","test_time_data = DataLoader(test_time_data, batch_size)\n","\n","# Make src mask for decoder with size:\n","# [batch_size*n_heads, output_sequence_length, enc_seq_len]\n","src_mask = utils.generate_square_subsequent_mask(\n","    dim1=output_sequence_length,\n","    dim2=enc_seq_len\n","    ).to(device)\n","\n","# Make tgt mask for decoder with size:\n","# [batch_size*n_heads, output_sequence_length, output_sequence_length]\n","tgt_mask = utils.generate_square_subsequent_mask( \n","    dim1=output_sequence_length,\n","    dim2=output_sequence_length\n","    ).to(device)\n","\n","# Initialize the model with the same architecture and initialization as when it was saved\n","model = tst.TimeSeriesTransformer(\n","    input_size=len(input_variables),\n","    dec_seq_len=enc_seq_len,\n","    batch_first=batch_first,\n","    num_predicted_features=len(input_variables) # 1 if univariate\n","    ).to(device)\n","\n","# Define the file path, same as the forecast_window\n","PATH = 'model/model4D_{}_{}.pth'.format(enc_seq_len, output_sequence_length)\n","\n","# Load the saved state dictionary into the model\n","model.load_state_dict(torch.load(PATH))\n","# Load the state dict into the model\n","# state_dict  = torch.load(PATH, map_location=torch.device('cpu'))\n","# model.load_state_dict(state_dict)\n","\n","loss_fn = torch.nn.HuberLoss().to(device)\n","# loss_fn = torch.nn.MSELoss().to(device)\n","\n","\n","\n","# Iterate over all (x,y) pairs in validation dataloader\n","with torch.no_grad():\n","    eval(model, test_time_data, src_mask, tgt_mask, loss_fn, batch_first, batch_size, input_size, PLOT_BIAS, PLOT_PREDICT, SCALER)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.13 ('cs285')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"60f28da990a82b6e9f66922c01f222c0916fbdfe01a81492b8c0a757a8864f6f"}}},"nbformat":4,"nbformat_minor":0}
